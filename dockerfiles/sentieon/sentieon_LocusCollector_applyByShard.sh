#!/usr/bin/env bash

# *******************************************
# Mark duplicates by shard in a sorted BAM file
# for a single sample.
# The sorted BAM file need to be pre-processed
# to add read groups.
# The sorted BAM file can be split by lanes, the
# code accept all the corresponding files as a list.
# Implemented to accept a list of score tables
# generated by LocusCollector in distributed mode.
# *******************************************

## Command line arguments
# Input shards file
shards_file=$1
# Text file containing a list of contiguous regions to use.
# Regions are divided by shards following the format
# @<shard_index>TAB<chr>:<start>-<end>,
# one region per line
shard_index=$2

# Output file
output_file=$3

# Other
optical_dup_pix_dist=$4
# The maximum offset between two duplicate clusters in order to consider them optical duplicates.
# This should be set to 100 for (circa 2011+) read names and typical flowcells.
# Structured flow cells (NovaSeq, HiSeq 4000, X) should use ~2500.
# For older conventions, distances could be to some fairly small number (e.g. 5-10 pixels).

# Input score tables
shift 4 # $@ stores all the input BAM files and tables

## Other settings
nt=$(nproc) # number of threads to use in computation,
            # set to number of cores in the server

# ******************************************
# 1. Create list of score tables
#    Create list on input files
# ******************************************
input_tables=""
input_files=""

for arg in $@; do
    # Check if the file has a .bam extension
    if [[ $arg == *.bam ]]; then
        input_files+=" -i $arg"
    # Check if the file has a .gz extension (.vcf.gz)
    elif [[ $arg == *.gz ]]; then
        input_tables+=" --score_info $arg"
    else
        echo "File with unknown extension: $arg"
        exit 1
    fi
done

# ******************************************
# 2. Create shards
# ******************************************
grep -P "\@${shard_index}\t" $shards_file | cut -f 2 > SHARDS_LIST

shards=""

# Reading shards
while read -r line;
  do
    shards+=" --shard $line"
  done <SHARDS_LIST

# ******************************************
# 3. Mark/remove duplicate reads.
# By ommiting the --rmdup option in Dedup
# we are only marking to match GATK Best Practices.
# ******************************************
sentieon driver -t $nt $input_files $shards --algo Dedup --optical_dup_pix_dist $optical_dup_pix_dist $input_tables $output_file || exit 1

# ******************************************
# 4. Check deduped BAM integrity.
# ******************************************
py_script="
import sys, os

def check_EOF(filename):
    EOF_hex = b'\x1f\x8b\x08\x04\x00\x00\x00\x00\x00\xff\x06\x00\x42\x43\x02\x00\x1b\x00\x03\x00\x00\x00\x00\x00\x00\x00\x00\x00'
    size = os.path.getsize(filename)
    fb = open(filename, 'rb')
    fb.seek(size - 28)
    EOF = fb.read(28)
    fb.close()
    if EOF != EOF_hex:
        sys.stderr.write('EOF is missing\n')
        sys.exit(1)
    else:
        sys.stderr.write('EOF is present\n')

check_EOF('${output_file}')
"

python -c "$py_script" || exit 1
